'''
generate xyz_crop '*.pkl'

usage: python xyz_crop.py --img_dir path/to/train_pbr

Note: The labels for 3D object coordinates are generated by backprojecting the 
rendered depths.
'''

import os,sys
o_path = os.getcwd()
sys.path.append(o_path)

import glob
from tqdm import tqdm
import cv2
import numpy as np
import json
import open3d as o3d
import _pickle as cPickle
from visual_points import visual_points
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--img_dir', type=str)
opt = parser.parse_args()

img_dir = opt.img_dir
# img_dir = 'datasets/BOP_DATASETS/lm/train_pbr/'

xmap = np.array([[i for i in range(640)] for j in range(480)])
ymap = np.array([[j for i in range(640)] for j in range(480)])
norm_scale = 1000.0*10

folder_list = [name for name in sorted(os.listdir(img_dir)) if os.path.isdir(os.path.join(img_dir, name))]
if 'xyz_crop' in folder_list:
    folder_list.remove('xyz_crop')

for folder in folder_list:
    print(folder + ':')
    mask_visib_paths = glob.glob(os.path.join(img_dir, folder, 'mask_visib','*.png'))
    mask_visib_paths = sorted(mask_visib_paths)
    assert len(mask_visib_paths)
    #load camera intrinsc matrix
    cam_inf_filename = os.path.join(img_dir, folder, 'scene_camera.json')
    with open(cam_inf_filename, "r") as f:
        cam_inf = json.load(f)
    #load gt
    gt_filename = os.path.join(img_dir, folder, 'scene_gt.json')
    with open(gt_filename, "r") as f:
        gt = json.load(f)
    #load gt sence info
    scene_inf_filename = os.path.join(img_dir, folder, 'scene_gt_info.json')
    with open(scene_inf_filename, "r") as f:
        scene_gt = json.load(f)    

    save_dir = os.path.join(img_dir, 'xyz_crop', folder)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    for mask_visib_path in tqdm(mask_visib_paths):
        img_name = os.path.basename(mask_visib_path)
        img_spliting = img_name.split('_')
        img_id = img_spliting[0]
        inst_id = img_spliting[1].split('.')[0]
        img_indx = str(int(img_id))
        inst_indx = int(inst_id)
        depth_path =os.path.join(img_dir, folder, 'depth', img_id +'.png')
        all_exist = os.path.exists(depth_path) and os.path.exists(mask_visib_path)
        if not all_exist:
            continue        
        # avoid repeated operations
        save_path = os.path.join(save_dir, '{}_{}-xyz.pkl'.format(img_id, inst_id))
        if os.path.exists(save_path):
            continue

        cam_k = cam_inf[img_indx]['cam_K']
        cam_fx, cam_fy, cam_cx, cam_cy = cam_k[0], cam_k[4], cam_k[2], cam_k[5]
        mask = cv2.imread(mask_visib_path, -1)
        assert mask.shape[0]==480 and mask.shape[1]==640 
        # cv2.imshow('mask', mask)
        # cv2.waitKey()        
        depth = cv2.imread(depth_path, -1) 
        depth_masked = depth * (mask!=0)
        #exclude invaild detph instance
        # if np.sum(depth_masked>0) < 64:
        #     continue
        depth_masked = depth_masked.flatten()[:, np.newaxis]
        xmap_masked = xmap.flatten()[:, np.newaxis]
        ymap_masked = ymap.flatten()[:, np.newaxis]
        # depth = depth.flatten()[:, np.newaxis]
        # pt2_ = depth / norm_scale
        # pt0_ = (xmap_masked - cam_cx) * pt2_ / cam_fx
        # pt1_ = (ymap_masked - cam_cy) * pt2_ / cam_fy
        # points_raw = np.concatenate((pt0_, pt1_, pt2_), axis=1)
        pt2 = depth_masked / norm_scale
        pt0 = (xmap_masked - cam_cx) * pt2 / cam_fx
        pt1 = (ymap_masked - cam_cy) * pt2 / cam_fy
        points = np.concatenate((pt0, pt1, pt2), axis=1)
        # backproject the rendered depths to get labels for 3D object coordinates
        gt_R = np.array(gt[img_indx][inst_indx]['cam_R_m2c']).reshape(3, 3)
        gt_t = np.array(gt[img_indx][inst_indx]['cam_t_m2c']).reshape(-1)/1000.0
        R = np.linalg.inv(gt_R)
        t = gt_t *(-1)
        RT = np.eye(4, 4)
        RT[:3, 3] = t
        pcd1 = o3d.geometry.PointCloud()
        pcd1.points = o3d.utility.Vector3dVector(points)
        pcd1.transform(RT)        
        RT = np.eye(4, 4)
        RT[:3, :3] = R
        pcd1.transform(RT)        
        # visual_points( points, np.asarray(pcd1.points), points_raw)        
        points_ = np.asarray(pcd1.points)
        xyz = points_.reshape(480, 640, -1)
        # cv2.imshow('image', xyz*255)
        # cv2.waitKey()
        #instance bboxes
        inst_bbox = scene_gt[img_indx][inst_indx]['bbox_visib']
        x1, y1, x2, y2 = inst_bbox[0], inst_bbox[1], inst_bbox[0]+inst_bbox[2], inst_bbox[1]+inst_bbox[3]
        rmin, rmax, cmin, cmax = inst_bbox[1], inst_bbox[1]+inst_bbox[3]+1,\
             inst_bbox[0], inst_bbox[0] + inst_bbox[2]+1 
        xyz_crop = xyz[rmin:rmax,cmin:cmax]
        XYZ = {}
        XYZ['xyz_crop'] = xyz_crop
        XYZ['xyxy'] = [x1, y1, x2, y2]

        with open(save_path, 'wb') as f:
            cPickle.dump(XYZ, f)   
